{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec4d0986-b515-407b-a81c-965f20a42e14",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover, Tokenizer, CountVectorizer\n",
    "from pyspark.sql.functions import split, col, regexp_replace, lower, concat_ws\n",
    "from pyspark.ml.linalg import Vectors\n",
    "import numpy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b27cab97-faf1-4d99-95a2-cdb9aaeba1d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize a dataframe with our reviews and their corresponding sentiment\n",
    "reviews_df = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").option(\"quote\", \"\\\"\").option(\"escape\", \"\\\"\").csv(\"/FileStore/tables/IMDB_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30db0022-5025-41e0-9c04-72d1778b6879",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#https://www.educative.io/answers/remove-all-the-punctuation-marks-from-a-sentence-using-regex\n",
    "#https://sqlpatterns.wordpress.com/2017/08/18/three-strategies-for-replacing-multiple-spaces-with-single-ones/\n",
    "\n",
    "# Remove any instances of line breaks from the reviews\n",
    "edited_df = reviews_df.select(regexp_replace('review', r'<br />', ' ').alias(\"review\"), \"sentiment\")\n",
    "# Remove any instances of non-word, non-space, and non-digit characters in reviews\n",
    "edited_df = edited_df.select(regexp_replace('review', '[^\\s\\w\\d]', '').alias(\"review\"), \"sentiment\")\n",
    "# Remove any instances of two or more spaces from reviews\n",
    "edited_df = edited_df.select(regexp_replace('review', '[ ][ ]+', ' ').alias(\"review\"), \"sentiment\")\n",
    "# Switch all words to lowercase to avoid any duplicity in tokenization later\n",
    "edited_df = edited_df.select(lower('review').alias(\"review\"), \"sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd61e5c3-61c9-4adb-b601-5cb4338d9070",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Split the reviews into a list format so that we can remove stopwords later on; keep sentiment information too\n",
    "split_reviews = edited_df.select(split(edited_df.review, \" \").alias('review_array'), \"sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a3c2804-4f16-4d3c-b6ab-52552059810a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize a stopword remover with the review array as input\n",
    "remover = StopWordsRemover(inputCol=\"review_array\", outputCol=\"filtered_review_array\")\n",
    "# Transform split_df with the remover to get a list of words per review that have stopwords removed\n",
    "stop_removed_df = remover.transform(split_reviews).select(\"filtered_review_array\", \"sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "caa5a342-6978-4211-8c64-15c00f85f5e7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Reconcatenate the list together to have a string version of our reviews. This will allow us to tokenize each review.\n",
    "stop_removed_df = stop_removed_df.withColumn(\"filtered_review\", concat_ws(\" \", \"filtered_review_array\")).select(\"filtered_review\", \"sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fec37a88-2c6c-42ea-977b-da66b48e140e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Make a tokenizer with filtered review as input\n",
    "tokenizer = Tokenizer(inputCol=\"filtered_review\", outputCol=\"words\")\n",
    "# Transform our stop_removed dataframe to obtain a final input of tokenized words we can count vectorize for Naive Bayes analysis\n",
    "fin_df = tokenizer.transform(stop_removed_df).select(\"words\", \"sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d3d30c1-14f9-49c6-b51a-6cf22a1a44ed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a count vectorizer to keep a bag-of-words count of our tokens\n",
    "cv = CountVectorizer(inputCol=\"words\", outputCol=\"features\")\n",
    "model = cv.fit(fin_df)\n",
    "vectorized_df = model.transform(fin_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59f0bef9-6e3a-4d79-84e7-e5bd37e4ea3b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Do a 70-30 split of our data into training and testing sets, respectively\n",
    "train_test_split = vectorized_df.randomSplit([0.7, 0.3])\n",
    "train_data = train_test_split[0]\n",
    "test_data = train_test_split[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfec15ce-5dc6-4746-b582-c381e689656c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Class = 'positive')\t 0.501209069443259 \nP(Class = 'negative')\t 0.4987909305567409\n"
     ]
    }
   ],
   "source": [
    "# Find P(class) for both sentiments (positive and negative)\n",
    "# To do so, just calculate the number of records that are of a class / the total number of records\n",
    "# This is our estimate of the prior associated with each class\n",
    "num_pos = train_data.filter(\"sentiment == 'positive'\").count()\n",
    "num_neg = train_data.filter(\"sentiment == 'negative'\").count()\n",
    "p_pos = num_pos / (num_pos + num_neg)\n",
    "p_neg = num_neg / (num_pos + num_neg)\n",
    "print(\"P(Class = 'positive')\\t\", p_pos, \"\\nP(Class = 'negative')\\t\", p_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "029df93b-df03-4676-b4ff-230507cfdffc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Split training set entries based off of class type\n",
    "pos_entries = train_data.filter(\"sentiment == 'positive'\")\n",
    "neg_entries = train_data.filter(\"sentiment == 'negative'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a83f7d2e-ace2-41d9-8e4c-18490b65cc64",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Select features column to get sparse vector\n",
    "# Convert sparse vector into ndarray that can be summed column-wise via a reduce function\n",
    "# This will yield an array with each index corresponding to a different unique token \n",
    "# where the value at the index is the total count of its occurrence across all documents\n",
    "pos_sum_arr = pos_entries.select(\"features\").rdd.map(lambda x: x[0].toArray()).reduce(lambda x, y: x+y)\n",
    "neg_sum_arr = neg_entries.select(\"features\").rdd.map(lambda x: x[0].toArray()).reduce(lambda x, y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fb8199c-3bd8-42fa-8419-78ecc49034ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# In order to obtain our P(Xi | Class), or our estimates of likelihoods, we should normalize these occurrence counts\n",
    "# We do this for cases where we are trying to find P(Xi | Positive) and P(Xi | Negative)\n",
    "normalized_pos_arr = pos_sum_arr / sum(pos_sum_arr)\n",
    "normalized_neg_arr = neg_sum_arr / sum(neg_sum_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6ed2e54-1634-40f5-a14f-639934954e21",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# For easier computation further in our notebook, we save the log probabilities we obtained in the cell above\n",
    "# These log probabilities can be summed later on, and probability values that don't contribute to the computation i.e. 0, \n",
    "# will be given a default value of 0s, which have no effect on a sum\n",
    "# https://stackoverflow.com/questions/21752989/numpy-efficiently-avoid-0s-when-taking-logmatrix\n",
    "log_pos_arr = numpy.log(normalized_pos_arr, out=numpy.zeros_like(normalized_pos_arr), where=(normalized_pos_arr!=0))\n",
    "log_neg_arr = numpy.log(normalized_neg_arr, out=numpy.zeros_like(normalized_neg_arr), where=(normalized_neg_arr!=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6205fc74-c603-4195-8c84-fa075319c1c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Custom function to classify a sparse vector of token occurrences (the review) into a sentiment\n",
    "# The computation follows the parameter estimation model for multinomial Naive Bayes where our vector can have non-binary elements\n",
    "# https://en.wikipedia.org/wiki/Naive_Bayes_classifier\n",
    "def classify_arr(x):\n",
    "    # Calculate the log probability of P(positive | X) and P(negative | X) excluding the denominator which is the same for both\n",
    "    p_arr_pos = math.log(p_pos) + x.features.dot(log_pos_arr)\n",
    "    p_arr_neg = math.log(p_neg) + x.features.dot(log_neg_arr)\n",
    "    # If the probability of it being positive is higher, we predict the review as positive and vice-versa\n",
    "    prediction = 1 if p_arr_pos > p_arr_neg else 0\n",
    "    # We also relabel the sentiments as 1 or 0 depending on if it is positive or negative respectively.\n",
    "    # Note that this is our truth / labels\n",
    "    binarized_sentiment = 1 if x.sentiment == \"positive\" else 0\n",
    "    # Return all necessary columns for further evaluation\n",
    "    return (x.features, binarized_sentiment, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b70f5a3-7405-4518-955a-697ed96c4253",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Make a dataframe where features are passed through and used for predictions for each record. Store the results in a dataframe\n",
    "predictions_df = test_data.select(\"features\", \"sentiment\").rdd.map(classify_arr).toDF([\"features\", \"sentiment\", \"prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "420d2c09-fcc5-48e6-b476-06c7a96b4d56",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Find the number of records present in our testing set\n",
    "num_records = predictions_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6374dfc8-df4b-43f6-8488-45778d416593",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Make a function that returns a 1 for correct predictions and a 0 otherwise\n",
    "def isCorrect(x):\n",
    "    return(1 if x.sentiment == x.prediction else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c91c959-3c4c-440b-9000-9ce427708add",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the number of predictions that were correct by summing values from isCorrect mapped over all predictions\n",
    "num_correct = predictions_df.rdd.map(isCorrect).reduce(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a429166d-5ff1-4a08-984e-2be3d22cd254",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 64.3208296855007 %\n"
     ]
    }
   ],
   "source": [
    "# Accuracy = number of correct records / total number of records\n",
    "print(\"Accuracy =\", (num_correct / num_records)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c64dd71f-198d-4fc6-85f3-2ba2470ebb6d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Priors for both classes:\nP(Class = 'positive')\t 0.501209069443259 \nP(Class = 'negative')\t 0.4987909305567409\n"
     ]
    }
   ],
   "source": [
    "print(\"Estimated Priors for both classes:\")\n",
    "print(\"P(Class = 'positive')\\t\", p_pos, \"\\nP(Class = 'negative')\\t\", p_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77a66073-96d4-4389-9510-93d1b1607654",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Likelihood values in vector form for both classes:\nP(X|Class = 'positive')\t [1.20707563e-02 1.33454455e-02 8.64588138e-03 ... 0.00000000e+00\n 0.00000000e+00 4.70191504e-07]\nP(X|Class = 'negative')\t [1.66292163e-02 1.20871898e-02 8.53586897e-03 ... 4.84689624e-07\n 0.00000000e+00 0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print(\"Estimated Likelihood values in vector form for both classes:\")\n",
    "# They are 1 x 167070 sized arrays\n",
    "print(\"P(X|Class = 'positive')\\t\", normalized_pos_arr)\n",
    "print(\"P(X|Class = 'negative')\\t\", normalized_neg_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c93a3ff2-dd95-4ba2-ae42-9cf310438a80",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Assignment 2 Question 2",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
